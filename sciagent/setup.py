"""äº¤äº’å¼é…ç½®å‘å¯¼æ¨¡å—"""

from __future__ import annotations

import json
from pathlib import Path
from typing import Dict, Optional, Any

# å»¶è¿Ÿå¯¼å…¥ä»¥é¿å…å¾ªç¯ä¾èµ–
def _lazy_import_agent_llm():
    """å»¶è¿Ÿå¯¼å…¥ AgentsLLM"""
    try:
        from .agent_llm import AgentsLLM
        return AgentsLLM
    except ImportError:
        return None

import questionary
from questionary import Style

from .ui import (
    print_banner,
    print_section_header,
    print_success,
    print_error,
    print_warning,
    print_info,
    print_step,
    create_info_panel,
    print_key_value,
    print_divider,
    console,
)
from .env_checker import EnvironmentChecker


# è‡ªå®šä¹‰æ ·å¼ä¸»é¢˜
custom_style = Style([
    ('qmark', 'fg:#673ab7 bold'),       # é—®é¢˜æ ‡è®°
    ('question', 'bold'),                # é—®é¢˜æ–‡æœ¬
    ('answer', 'fg:#f44336 bold'),      # å›ç­”
    ('pointer', 'fg:#673ab7 bold'),     # æŒ‡é’ˆ
    ('highlighted', 'fg:#673ab7 bold'), # é«˜äº®
    ('selected', 'fg:#cc5454'),         # å·²é€‰æ‹©
    ('separator', 'fg:#cc5454'),        # åˆ†éš”ç¬¦
    ('instruction', ''),                 # æŒ‡ä»¤
    ('text', ''),                        # æ–‡æœ¬
    ('disabled', 'fg:#858585 italic')   # ç¦ç”¨
])


class SetupWizard:
    """é…ç½®å‘å¯¼"""

    def __init__(self):
        self.config: Dict[str, Any] = {}
        self.workdir: Optional[Path] = None

    def run(self) -> bool:
        """è¿è¡Œé…ç½®å‘å¯¼"""
        print_banner()
        
        console.print(
            "[dim]æ¬¢è¿ä½¿ç”¨ SciAgent! è®©æˆ‘ä»¬é€šè¿‡å‡ ä¸ªç®€å•çš„æ­¥éª¤æ¥é…ç½®æ‚¨çš„ç¯å¢ƒã€‚[/dim]"
        )
        console.print()
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰é…ç½®
        existing_config_path = Path.cwd() / ".sciagent.json"
        if existing_config_path.exists():
            console.print()
            print_warning("âš ï¸  æ£€æµ‹åˆ°å·²å­˜åœ¨çš„é…ç½®æ–‡ä»¶")
            console.print()
            
            try:
                choice = questionary.select(
                    "å¦‚ä½•å¤„ç†ç°æœ‰é…ç½®ï¼Ÿ",
                    choices=[
                        "å®Œå…¨é‡æ–°é…ç½®ï¼ˆè¦†ç›–æ‰€æœ‰è®¾ç½®ï¼‰",
                        "åªæ›´æ–° AI é…ç½®",
                        "å–æ¶ˆï¼Œä¿ç•™ç°æœ‰é…ç½®"
                    ],
                    style=custom_style
                ).ask()
                
                if choice == "å–æ¶ˆï¼Œä¿ç•™ç°æœ‰é…ç½®":
                    print_info("å·²å–æ¶ˆé…ç½®")
                    return False
                elif choice == "åªæ›´æ–° AI é…ç½®":
                    # åªè¿è¡Œ AI é…ç½®éƒ¨åˆ†
                    print_info("æ­£åœ¨æ›´æ–° AI é…ç½®...")
                    console.print()
                    return self._update_ai_config_only()
                # else: ç»§ç»­å®Œæ•´é…ç½®æµç¨‹ï¼ˆè¦†ç›–ï¼‰
                console.print()
                print_warning("å°†è¦†ç›–ç°æœ‰é…ç½®...")
                console.print()
            except KeyboardInterrupt:
                console.print()
                print_info("å·²å–æ¶ˆé…ç½®")
                return False
        
        # ç¬¬ä¸€æ­¥ï¼šç¯å¢ƒæ£€æµ‹
        if not self._step_environment_check():
            return False
        
        # ç¬¬äºŒæ­¥ï¼šé¡¹ç›®é…ç½®
        if not self._step_project_setup():
            return False
        
        # ç¬¬ä¸‰æ­¥ï¼šé«˜çº§é…ç½®
        if not self._step_advanced_config():
            return False
        
        # ç¬¬å››æ­¥ï¼šä¿å­˜é…ç½®
        if not self._step_save_config():
            return False
        
        # å®Œæˆ
        self._step_completion()
        
        return True

    def _step_environment_check(self) -> bool:
        """æ­¥éª¤1ï¼šç¯å¢ƒæ£€æµ‹"""
        print_section_header("ğŸ“‹ æ­¥éª¤ 1/4: ç¯å¢ƒæ£€æµ‹")
        
        print_info("æ­£åœ¨æ£€æµ‹æ‚¨çš„ç³»ç»Ÿç¯å¢ƒ...")
        console.print()
        
        checker = EnvironmentChecker()
        checker.run_all_checks()
        console.print()
        checker.print_results()
        
        summary = checker.get_summary()
        console.print()
        
        if summary["failed"] > 0:
            print_warning(
                f"å‘ç° {summary['failed']} ä¸ªé—®é¢˜ï¼Œä½†æ‚¨ä»å¯ä»¥ç»§ç»­ã€‚"
            )
            
            continue_anyway = questionary.confirm(
                "æ˜¯å¦ç»§ç»­é…ç½®ï¼Ÿ",
                default=True,
                style=custom_style
            ).ask()
            
            if not continue_anyway:
                print_info("é…ç½®å·²å–æ¶ˆã€‚")
                return False
        else:
            print_success("æ‰€æœ‰æ£€æµ‹é€šè¿‡ï¼")
        
        console.print()
        return True

    def _step_project_setup(self) -> bool:
        """æ­¥éª¤2ï¼šé¡¹ç›®é…ç½®"""
        print_section_header("ğŸ¯ æ­¥éª¤ 2/4: é¡¹ç›®é…ç½®")
        
        # å·¥ä½œç›®å½•
        default_workdir = Path.cwd()
        workdir_input = questionary.path(
            "é€‰æ‹©å·¥ä½œç›®å½•:",
            default=str(default_workdir),
            style=custom_style
        ).ask()
        
        if not workdir_input:
            return False
        
        self.workdir = Path(workdir_input).expanduser().resolve()
        self.config["workdir"] = str(self.workdir)
        
        # é¡¹ç›®åç§°
        project_name = questionary.text(
            "é¡¹ç›®åç§°:",
            default=self.workdir.name,
            style=custom_style
        ).ask()
        
        if not project_name:
            return False
        
        self.config["project_name"] = project_name
        
        # çŠ¶æ€ç›®å½•
        state_dir = questionary.path(
            "SciAgent çŠ¶æ€ä¿å­˜ç›®å½•:",
            default=str(self.workdir / ".sciagent"),
            style=custom_style
        ).ask()
        
        if not state_dir:
            return False
        
        self.config["state_dir"] = state_dir
        
        console.print()
        print_success(f"é¡¹ç›®åç§°: {project_name}")
        print_success(f"å·¥ä½œç›®å½•: {self.workdir}")
        console.print()
        
        return True

    def _step_advanced_config(self) -> bool:
        """æ­¥éª¤3ï¼šé«˜çº§é…ç½®"""
        print_section_header("âš™ï¸  æ­¥éª¤ 3/4: é«˜çº§é…ç½®")
        
        # æ˜¯å¦é…ç½®é«˜çº§é€‰é¡¹
        configure_advanced = questionary.confirm(
            "æ˜¯å¦é…ç½®é«˜çº§é€‰é¡¹ï¼Ÿ",
            default=False,
            style=custom_style
        ).ask()
        
        if not configure_advanced:
            console.print()
            print_info("è·³è¿‡é«˜çº§é…ç½®ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®ã€‚")
            console.print()
            return True
        
        console.print()
        
        # ä¸»è¦ç›‘æ§æŒ‡æ ‡é…ç½®
        metric_choice = questionary.select(
            "ä¸»è¦ç›‘æ§æŒ‡æ ‡ï¼ˆç”¨äºå¯¹æ¯”å†å²è¿è¡Œï¼‰å¦‚ä½•ç¡®å®šï¼Ÿ",
            choices=[
                "è‡ªåŠ¨æ£€æµ‹ï¼ˆæ¨èï¼‰- ç³»ç»Ÿä¼šæ™ºèƒ½è¯†åˆ«æœ€é‡è¦çš„æŒ‡æ ‡",
                "æ‰‹åŠ¨æŒ‡å®š - è‡ªå·±è¾“å…¥æŒ‡æ ‡åç§°"
            ],
            style=custom_style
        ).ask()
        
        if metric_choice and "æ‰‹åŠ¨æŒ‡å®š" in metric_choice:
            primary_metric = questionary.text(
                "è¯·è¾“å…¥ä¸»è¦ç›‘æ§æŒ‡æ ‡åç§° (å¦‚ accuracy, f1_score, loss):",
                default="",
                style=custom_style
            ).ask()
            
            if primary_metric:
                self.config["primary_metric"] = primary_metric
                print_success(f"âœ“ ä¸»è¦æŒ‡æ ‡å·²è®¾ç½®: {primary_metric}")
            else:
                print_info("æœªè®¾ç½®ä¸»è¦æŒ‡æ ‡ï¼Œå°†ä½¿ç”¨è‡ªåŠ¨æ£€æµ‹")
        else:
            print_info("âœ“ å°†ä½¿ç”¨è‡ªåŠ¨æ£€æµ‹ï¼ˆä» accuracy, f1, loss ç­‰å¸¸è§æŒ‡æ ‡ä¸­æ™ºèƒ½é€‰æ‹©ï¼‰")
        
        console.print()
        
        # æ˜¯å¦å¯ç”¨ Git é›†æˆ
        enable_git = questionary.confirm(
            "æ˜¯å¦å¯ç”¨ Git é›†æˆ (è®°å½• commit hash)?",
            default=True,
            style=custom_style
        ).ask()
        
        self.config["enable_git"] = enable_git
        
        # æ˜¯å¦å¯ç”¨ AI åˆ†æ
        enable_ai = questionary.confirm(
            "æ˜¯å¦å¯ç”¨ AI åˆ†æåŠŸèƒ½ (éœ€è¦é…ç½® LLM API)?",
            default=True,
            style=custom_style
        ).ask()
        
        self.config["enable_ai"] = enable_ai
        
        if enable_ai:
            console.print()
            print_info("AI åˆ†æåŠŸèƒ½éœ€è¦é…ç½® LLM APIï¼ˆå¦‚ OpenAIã€DeepSeekã€é€šä¹‰åƒé—®ç­‰ï¼‰")
            print_info("è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®ç›¸å…³ç¯å¢ƒå˜é‡")
            print_info("å‚è€ƒ: .env.example")
            
            # è¯¢é—®æ˜¯å¦ç°åœ¨é…ç½®
            configure_now = questionary.confirm(
                "æ˜¯å¦ç°åœ¨é…ç½® LLM API?",
                default=False,
                style=custom_style
            ).ask()
            
            if configure_now:
                self._configure_llm_api()
        
        console.print()
        return True

    def _step_save_config(self) -> bool:
        """æ­¥éª¤4ï¼šä¿å­˜é…ç½®"""
        print_section_header("ğŸ’¾ æ­¥éª¤ 4/4: ä¿å­˜é…ç½®")
        
        # æ˜¾ç¤ºé…ç½®æ‘˜è¦
        console.print("[bold]é…ç½®æ‘˜è¦:[/bold]")
        console.print()
        
        print_key_value("é¡¹ç›®åç§°", self.config.get("project_name"))
        print_key_value("å·¥ä½œç›®å½•", self.config.get("workdir"))
        print_key_value("çŠ¶æ€ç›®å½•", self.config.get("state_dir"))
        
        if self.config.get("enable_ai"):
            print_key_value("AI åˆ†æ", f"å·²å¯ç”¨ ({self.config.get('llm_provider', 'auto')})")
        else:
            print_key_value("AI åˆ†æ", "æœªå¯ç”¨")
        
        console.print()
        print_divider()
        console.print()
        
        # ç¡®è®¤ä¿å­˜
        confirm_save = questionary.confirm(
            "ç¡®è®¤ä¿å­˜é…ç½®ï¼Ÿ",
            default=True,
            style=custom_style
        ).ask()
        
        if not confirm_save:
            print_warning("é…ç½®æœªä¿å­˜ã€‚")
            return False
        
        # ä¿å­˜é…ç½®æ–‡ä»¶
        config_file = Path(self.config["workdir"]) / ".sciagent.json"
        
        try:
            config_file.parent.mkdir(parents=True, exist_ok=True)
            with open(config_file, "w", encoding="utf-8") as f:
                json.dump(self.config, f, indent=2, ensure_ascii=False)
            
            console.print()
            print_success(f"é…ç½®å·²ä¿å­˜åˆ°: {config_file}")
            
        except Exception as e:
            print_error(f"ä¿å­˜é…ç½®å¤±è´¥: {e}")
            return False
        
        console.print()
        return True

    def _configure_llm_api(self):
        """é…ç½® LLM API - äº¤äº’å¼é€‰æ‹©ï¼ˆæ”¯æŒé‡è¯•ï¼‰"""
        console.print()
        print_info("è®©æˆ‘ä»¬é…ç½® AI åˆ†æåŠŸèƒ½æ‰€éœ€çš„ LLM API")
        console.print()
        
        # å¤–å±‚å¾ªç¯ï¼šå…è®¸é‡æ–°é€‰æ‹©æä¾›å•†
        while True:
            result = self._configure_llm_api_inner()
            if result in ["success", "skip"]:
                break
            elif result == "retry_provider":
                console.print()
                print_info("é‡æ–°é€‰æ‹©æä¾›å•†...")
                console.print()
                continue
            else:  # "cancel"
                print_warning("å·²å–æ¶ˆ AI é…ç½®")
                break
    
    def _configure_llm_api_inner(self):
        """å†…éƒ¨é…ç½®å‡½æ•°ï¼ˆå•æ¬¡å°è¯•ï¼‰"""
        # æä¾›å•†ä¿¡æ¯å­—å…¸
        provider_info = {
            "openai": {
                "name": "OpenAI",
                "default_model": "gpt-5.1",
                "models": ["gpt-5.1", "gpt-5-mini", "gpt-5.1-codex", "gpt-4.1"],
                "api_key_hint": "sk-proj-...",
                "website": "https://platform.openai.com/",
                "need_vpn": True
            },
            "deepseek": {
                "name": "DeepSeek",
                "default_model": "deepseek-chat",
                "models": ["deepseek-chat", "deepseek-reasoner"],
                "api_key_hint": "sk-...",
                "website": "https://platform.deepseek.com/",
                "need_vpn": False
            },
            "qwen": {
                "name": "é€šä¹‰åƒé—® (Qwen)",
                "default_model": "qwen-plus",
                "models": ["qwen-plus", "qwen-max"],
                "api_key_hint": "sk-...",
                "website": "https://dashscope.console.aliyun.com/",
                "need_vpn": False
            },
            "kimi": {
                "name": "Kimi (Moonshot)",
                "default_model": "moonshot-v1-8k",
                "models": ["moonshot-v1-8k", "moonshot-v1-32k", "moonshot-v1-128k"],
                "api_key_hint": "sk-...",
                "website": "https://platform.moonshot.cn/",
                "need_vpn": False
            },
            "zhipu": {
                "name": "æ™ºè°± AI (GLM)",
                "default_model": "glm-4.6",
                "models": ["glm-4.6", "glm-4.5", "glm-4.5-air", "glm-4.5-flash"],
                "api_key_hint": "xxx",
                "website": "https://open.bigmodel.cn/",
                "need_vpn": False
            },
            "gemini": {
                "name": "Gemini (Google)",
                "default_model": "gemini-2.5-flash",
                "models": ["gemini-2.5-pro", "gemini-2.5-flash"],
                "api_key_hint": "AIza...",
                "website": "https://ai.google.dev/",
                "need_vpn": True
            },
            "claude": {
                "name": "Claude (Anthropic)",
                "default_model": "claude-sonnet-4-5",
                "models": ["claude-sonnet-4-5", "claude-haiku-4-5", "claude-opus-4-1"],
                "api_key_hint": "sk-ant-...",
                "website": "https://console.anthropic.com/",
                "need_vpn": True
            },
            "custom": {
                "name": "è‡ªå®šä¹‰ APIï¼ˆä»»ä½• OpenAI å…¼å®¹æ¥å£ï¼‰",
                "default_model": "gpt-3.5-turbo",
                "models": [],
                "api_key_hint": "your-api-key",
                "website": "",
                "need_vpn": False
            }
        }
        
        # æ˜¾ç¤ºæä¾›å•†åˆ—è¡¨
        provider_choices = []
        for key, info in provider_info.items():
            vpn_tag = " ğŸŒéœ€è¦VPN" if info.get("need_vpn") else ""
            label = f"{info['name']}{vpn_tag}"
            provider_choices.append({"name": label, "value": key})
        
        provider = questionary.select(
            "é€‰æ‹© LLM æä¾›å•†:",
            choices=provider_choices,
            style=custom_style
        ).ask()
        
        if not provider:
            return "cancel"
        
        info = provider_info[provider]
        
        # å†…å±‚å¾ªç¯ï¼šå…è®¸é‡è¯•å½“å‰æä¾›å•†çš„é…ç½®
        while True:
            console.print()
            print_key_value("æä¾›å•†", info['name'])
            print_key_value("æ¨èæ¨¡å‹", info['default_model'])
            if info['website']:
                print_key_value("è·å– API Key", info['website'])
            console.print()
            
            # é€‰æ‹©æˆ–è¾“å…¥æ¨¡å‹
            if info['models']:
                use_custom_model = False
                model_choices = info['models'] + ["å…¶ä»–ï¼ˆæ‰‹åŠ¨è¾“å…¥ï¼‰"]
                
                model = questionary.select(
                    "é€‰æ‹©æ¨¡å‹:",
                    choices=model_choices,
                    default=info['default_model'],
                    style=custom_style
                ).ask()
                
                if model == "å…¶ä»–ï¼ˆæ‰‹åŠ¨è¾“å…¥ï¼‰":
                    use_custom_model = True
                
                if use_custom_model or not model:
                    model = questionary.text(
                        "è¾“å…¥æ¨¡å‹åç§°:",
                        default=info['default_model'],
                        style=custom_style
                    ).ask()
            else:
                model = questionary.text(
                    "è¾“å…¥æ¨¡å‹åç§°:",
                    default=info['default_model'],
                    style=custom_style
                ).ask()
            
            # è¾“å…¥ API Key
            api_key = questionary.password(
                f"è¾“å…¥ API Key (ç¤ºä¾‹: {info['api_key_hint']}):",
                style=custom_style
            ).ask()
            
            if not api_key:
                print_warning("æœªè¾“å…¥ API Key")
                retry_choice = questionary.select(
                    "æ¥ä¸‹æ¥?",
                    choices=[
                        "é‡æ–°è¾“å…¥",
                        "æ¢ä¸ªæä¾›å•†",
                        "è·³è¿‡ AI é…ç½®"
                    ],
                    style=custom_style
                ).ask()
                if retry_choice == "é‡æ–°è¾“å…¥":
                    continue
                elif retry_choice == "æ¢ä¸ªæä¾›å•†":
                    return "retry_provider"
                else:
                    return "skip"
            
            # Base URL é…ç½®
            if provider == "custom":
                base_url = questionary.text(
                    "è¾“å…¥ API Base URL:",
                    default="http://localhost:8080/v1",
                    style=custom_style
                ).ask()
            else:
                base_url = None  # ä½¿ç”¨é»˜è®¤
            
            # æµ‹è¯•è¿æ¥
            console.print()
            test_connection = questionary.confirm(
                "æ˜¯å¦æµ‹è¯• API è¿æ¥?",
                default=True,
                style=custom_style
            ).ask()
            
            connection_ok = True
            if test_connection:
                if self._test_llm_connection(provider, api_key, base_url, model):
                    console.print()
                    print_success("âœ“ API è¿æ¥æµ‹è¯•æˆåŠŸï¼")
                    console.print()
                else:
                    console.print()
                    print_warning("âš ï¸  API è¿æ¥æµ‹è¯•å¤±è´¥")
                    console.print()
                    
                    # æä¾›å¤šä¸ªé€‰é¡¹
                    retry_choice = questionary.select(
                        "æ¥ä¸‹æ¥?",
                        choices=[
                            "é‡æ–°è¾“å…¥ API Key",
                            "é‡æ–°é€‰æ‹©æ¨¡å‹",
                            "æ¢ä¸ªæä¾›å•†",
                            "è·³è¿‡æµ‹è¯•ï¼Œç›´æ¥ä¿å­˜",
                            "æ”¾å¼ƒ AI é…ç½®"
                        ],
                        style=custom_style
                    ).ask()
                    
                    if retry_choice == "é‡æ–°è¾“å…¥ API Key":
                        continue  # é‡æ–°å¼€å§‹å½“å‰æä¾›å•†çš„é…ç½®
                    elif retry_choice == "é‡æ–°é€‰æ‹©æ¨¡å‹":
                        continue  # é‡æ–°å¼€å§‹å½“å‰æä¾›å•†çš„é…ç½®
                    elif retry_choice == "æ¢ä¸ªæä¾›å•†":
                        return "retry_provider"  # å›åˆ°å¤–å±‚å¾ªç¯
                    elif retry_choice == "è·³è¿‡æµ‹è¯•ï¼Œç›´æ¥ä¿å­˜":
                        print_info("è·³è¿‡æµ‹è¯•ï¼Œä¿å­˜é…ç½®...")
                        connection_ok = True  # å…è®¸ä¿å­˜
                    else:  # "æ”¾å¼ƒ AI é…ç½®"
                        return "cancel"
            
            # ä¿å­˜åˆ°é…ç½®
            self.config["llm_provider"] = provider
            self.config["llm_api_key"] = api_key
            self.config["llm_model"] = model or info['default_model']
            if base_url:
                self.config["llm_base_url"] = base_url
            
            console.print()
            print_success("âœ“ LLM API é…ç½®å·²ä¿å­˜")
            print_info(f"æä¾›å•†: {info['name']}")
            print_info(f"æ¨¡å‹: {self.config['llm_model']}")
            console.print()
            
            return "success"
    
    def _test_llm_connection(self, provider: str, api_key: str, base_url: Optional[str], model: str) -> bool:
        """æµ‹è¯• LLM API è¿æ¥"""
        try:
            AgentsLLM = _lazy_import_agent_llm()
            if not AgentsLLM:
                print_warning("æ— æ³•å¯¼å…¥ AgentsLLM æ¨¡å—")
                return False
            
            print_info("æ­£åœ¨æµ‹è¯• API è¿æ¥...")
            
            # ä¸´æ—¶åˆ›å»º LLM å®ä¾‹
            llm = AgentsLLM(
                provider=provider,
                api_key=api_key,
                base_url=base_url,
                model=model,
                timeout=10
            )
            
            # å‘é€ä¸€ä¸ªç®€å•çš„æµ‹è¯•è¯·æ±‚
            test_messages = [
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": "Say 'OK' if you can read this."}
            ]
            
            response_text = ""
            for chunk in llm.think(test_messages, temperature=0):
                response_text += chunk
                if len(response_text) > 10:  # æ”¶åˆ°å“åº”å°±ç®—æˆåŠŸ
                    break
            
            return True
            
        except Exception as e:
            print_error(f"è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)[:100]}")
            return False
    
    def _create_env_example(self):
        """åˆ›å»º .env ç¤ºä¾‹æ–‡ä»¶"""
        env_example_path = Path(self.config["workdir"]) / ".env.example"
        
        env_content = """# SciAgent LLM é…ç½®ç¤ºä¾‹
# å¤åˆ¶æ­¤æ–‡ä»¶ä¸º .env å¹¶å¡«å…¥å®é™…çš„ API å¯†é’¥

# é€šç”¨é…ç½®ï¼ˆé€‚ç”¨äºæ‰€æœ‰æä¾›å•†ï¼‰
# LLM_API_KEY=your_api_key_here
# LLM_BASE_URL=https://api.example.com/v1
# LLM_MODEL_ID=model_name

# OpenAI
# OPENAI_API_KEY=sk-...

# DeepSeek
# DEEPSEEK_API_KEY=sk-...

# é€šä¹‰åƒé—® (Qwen)
# DASHSCOPE_API_KEY=sk-...

# Kimi (Moonshot)
# KIMI_API_KEY=sk-...
# MOONSHOT_API_KEY=sk-...

# æ™ºè°± AI (GLM)
# ZHIPU_API_KEY=...
# GLM_API_KEY=...

# Ollama (æœ¬åœ°)
# OLLAMA_HOST=http://localhost:11434/v1
# OLLAMA_API_KEY=ollama

# å…¶ä»–å‚æ•°
# LLM_TEMPERATURE=0.7
# LLM_MAX_TOKENS=2000
# LLM_TIMEOUT=60
"""
        
        try:
            with open(env_example_path, "w", encoding="utf-8") as f:
                f.write(env_content)
            print_success(f".env ç¤ºä¾‹å·²ä¿å­˜åˆ°: {env_example_path}")
            print_info("è¯·å¤åˆ¶ .env.example ä¸º .env å¹¶å¡«å…¥å®é™…çš„ API å¯†é’¥")
        except Exception as e:
            print_warning(f"ä¿å­˜ .env ç¤ºä¾‹å¤±è´¥: {e}")
    
    def _step_completion(self):
        """å®Œæˆæ­¥éª¤"""
        console.print()
        print_divider()
        console.print()
        
        completion_text = (
            "SciAgent å·²æˆåŠŸé…ç½®ï¼æ‚¨ç°åœ¨å¯ä»¥å¼€å§‹ä½¿ç”¨äº†ã€‚\n\n"
            "å¿«é€Ÿå¼€å§‹:\n"
            f"  sciagent run --cmd 'python train.py' --workdir {self.config['workdir']}\n\n"
            "æŸ¥çœ‹å¸®åŠ©:\n"
            "  sciagent --help\n\n"
            "æŸ¥çœ‹è¿è¡Œå†å²:\n"
            "  sciagent history"
        )
        
        # å¦‚æœå¯ç”¨äº† AIï¼Œæ·»åŠ ç›¸å…³è¯´æ˜
        if self.config.get("enable_ai"):
            completion_text += (
                "\n\nAI åˆ†æåŠŸèƒ½:\n"
                "  sciagent analyze              # åˆ†ææœ€æ–°è¿è¡Œ\n"
                "  sciagent analyze --run-id XXX  # åˆ†ææŒ‡å®šè¿è¡Œ\n\n"
                "ğŸ’¡ æç¤º: è¯·é…ç½® .env æ–‡ä»¶ä»¥ä½¿ç”¨ AI åˆ†æåŠŸèƒ½"
            )
        
        create_info_panel(
            "âœ¨ é…ç½®å®Œæˆï¼",
            completion_text,
            style="green"
        )
        
        console.print()
    
    def _update_ai_config_only(self) -> bool:
        """åªæ›´æ–° AI é…ç½®ï¼ˆä¸æ”¹å˜å…¶ä»–è®¾ç½®ï¼‰"""
        config_file = Path.cwd() / ".sciagent.json"
        
        # è¯»å–ç°æœ‰é…ç½®
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                self.config = json.load(f)
            
            print_success("âœ“ å·²åŠ è½½ç°æœ‰é…ç½®")
            console.print()
        except Exception as e:
            print_error(f"è¯»å–é…ç½®å¤±è´¥: {e}")
            return False
        
        # è¿è¡Œ AI é…ç½®
        self._configure_llm_api()
        
        # ä¿å­˜æ›´æ–°åçš„é…ç½®
        try:
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(self.config, f, indent=2, ensure_ascii=False)
            
            console.print()
            print_success(f"âœ“ AI é…ç½®å·²æ›´æ–°: {config_file}")
            console.print()
            return True
        except Exception as e:
            print_error(f"ä¿å­˜é…ç½®å¤±è´¥: {e}")
            return False


def run_init_wizard() -> int:
    """è¿è¡Œåˆå§‹åŒ–å‘å¯¼"""
    wizard = SetupWizard()
    
    try:
        success = wizard.run()
        return 0 if success else 1
    except KeyboardInterrupt:
        console.print()
        print_warning("é…ç½®å·²å–æ¶ˆã€‚")
        return 1
    except Exception as e:
        console.print()
        print_error(f"é…ç½®è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return 1

