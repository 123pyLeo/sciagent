"""å®éªŒæ•°æ®å¯¼å‡ºæ¨¡å— - ç”¨äºç”Ÿæˆå‘¨æŠ¥ã€æ¶ˆèè¡¨æ ¼ç­‰"""

from __future__ import annotations

import json
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta

from .ui import print_success, print_error, print_info, console
from .code_tracker import generate_code_change_summary


class ExperimentExporter:
    """å®éªŒæ•°æ®å¯¼å‡ºå™¨"""
    
    def __init__(self, state_dir: Path):
        """
        åˆå§‹åŒ–å¯¼å‡ºå™¨
        
        Args:
            state_dir: SciAgent çŠ¶æ€ç›®å½•
        """
        self.state_dir = state_dir
        self.history_file = state_dir / "history.json"
        self.runs_dir = state_dir / "runs"
    
    def load_history(self) -> List[Dict[str, Any]]:
        """åŠ è½½å†å²è®°å½•"""
        if not self.history_file.exists():
            return []
        
        try:
            with open(self.history_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('runs', [])
        except Exception as e:
            print_error(f"åŠ è½½å†å²è®°å½•å¤±è´¥: {e}")
            return []
    
    def load_run_details(self, run_id: str) -> Optional[Dict[str, Any]]:
        """åŠ è½½è¿è¡Œè¯¦ç»†ä¿¡æ¯"""
        run_record_file = self.runs_dir / run_id / "run_record.json"
        if not run_record_file.exists():
            return None
        
        try:
            with open(run_record_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            return None
    
    def filter_runs(
        self,
        runs: List[Dict[str, Any]],
        name_pattern: Optional[str] = None,
        since_days: Optional[int] = None,
        metadata_filter: Optional[Dict[str, str]] = None
    ) -> List[Dict[str, Any]]:
        """
        ç­›é€‰è¿è¡Œè®°å½•
        
        Args:
            runs: è¿è¡Œè®°å½•åˆ—è¡¨
            name_pattern: åç§°æ¨¡å¼ï¼ˆåŒ…å«åŒ¹é…ï¼‰
            since_days: æœ€è¿‘å‡ å¤©å†…
            metadata_filter: å…ƒæ•°æ®ç­›é€‰æ¡ä»¶
            
        Returns:
            ç­›é€‰åçš„è¿è¡Œè®°å½•
        """
        filtered = runs
        
        # æŒ‰åç§°ç­›é€‰
        if name_pattern:
            filtered = [r for r in filtered if name_pattern in r.get('name', '')]
        
        # æŒ‰æ—¶é—´ç­›é€‰
        if since_days is not None:
            # ä½¿ç”¨ UTC æ—¶é—´ä½œä¸ºåŸºå‡†ï¼ˆå› ä¸ºè®°å½•çš„æ—¶é—´é€šå¸¸æ˜¯ UTCï¼‰
            cutoff = datetime.utcnow() - timedelta(days=since_days)
            
            def is_within_timeframe(run):
                # ä¼˜å…ˆä½¿ç”¨ start_timeï¼Œfallback åˆ° ended_atï¼ˆå…¼å®¹æ—§æ ¼å¼ï¼‰
                time_str = run.get('start_time') or run.get('ended_at', '')
                if not time_str:  # è·³è¿‡ç©ºå­—ç¬¦ä¸²æˆ– None
                    return False
                try:
                    # å»æ‰æ—¶åŒºä¿¡æ¯ï¼Œç»Ÿä¸€ç”¨ naive datetime æ¯”è¾ƒ
                    # 1. å»æ‰å°¾éƒ¨çš„ 'Z'ï¼ˆUTC æ ‡è¯†ï¼‰
                    time_str = time_str.rstrip('Z')
                    
                    # 2. å»æ‰ '+XX:XX' æˆ– '-XX:XX' æ—¶åŒºåç§»
                    # æ‰¾åˆ° 'T' åé¢çš„ç¬¬ä¸€ä¸ª '+' æˆ–æœ€åä¸€ä¸ª '-'ï¼ˆæ—¶åŒºæ ‡è®°ï¼‰
                    if 'T' in time_str:
                        date_time_parts = time_str.split('T')
                        time_part = date_time_parts[1]
                        # å»æ‰æ—¶åŒºåç§»
                        if '+' in time_part:
                            time_part = time_part.split('+')[0]
                        elif time_part.count('-') > 0:
                            # æ—¶é—´éƒ¨åˆ†ä¸åº”è¯¥æœ‰ '-'ï¼Œå¦‚æœæœ‰å°±æ˜¯æ—¶åŒº
                            time_part = time_part.split('-')[0]
                        time_str = f"{date_time_parts[0]}T{time_part}"
                    
                    # 3. å¤„ç†å°æ•°ç§’ï¼ˆä¿ç•™æœ€å¤š6ä½ï¼‰
                    if '.' in time_str:
                        base, frac = time_str.rsplit('.', 1)
                        time_str = f"{base}.{frac[:6]}"
                    
                    run_time = datetime.fromisoformat(time_str)
                    return run_time >= cutoff
                except (ValueError, TypeError):
                    # æ—¶é—´æ ¼å¼é”™è¯¯ï¼Œè·³è¿‡è¿™æ¡è®°å½•
                    return False
            
            filtered = [r for r in filtered if is_within_timeframe(r)]
        
        # æŒ‰å…ƒæ•°æ®ç­›é€‰
        if metadata_filter:
            def matches_metadata(run):
                run_metadata = run.get('metadata', {})
                return all(
                    run_metadata.get(k) == v 
                    for k, v in metadata_filter.items()
                )
            filtered = [r for r in filtered if matches_metadata(r)]
        
        return filtered
    
    def generate_summary(
        self,
        since_days: int = 7,
        name_pattern: Optional[str] = None,
        include_code_changes: bool = True,
        use_ai_for_code: bool = False,
        llm_config: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        ç”Ÿæˆå‘¨æŠ¥æ‘˜è¦
        
        Args:
            since_days: æœ€è¿‘å‡ å¤©ï¼ˆé»˜è®¤7å¤©ï¼‰
            name_pattern: åç§°ç­›é€‰
            
        Returns:
            Markdown æ ¼å¼çš„æ‘˜è¦
        """
        runs = self.load_history()
        
        # ç­›é€‰
        filtered = self.filter_runs(runs, name_pattern=name_pattern, since_days=since_days)
        
        if not filtered:
            return f"# å®éªŒæ‘˜è¦\n\næœ€è¿‘ {since_days} å¤©å†…æ²¡æœ‰å®éªŒè®°å½•ã€‚\n"
        
        # æ’åºï¼ˆæŒ‰æ—¶é—´ï¼‰
        filtered.sort(key=lambda r: r.get('start_time', ''), reverse=True)
        
        # ç”Ÿæˆæ‘˜è¦
        lines = []
        lines.append(f"# å®éªŒæ‘˜è¦ï¼ˆæœ€è¿‘ {since_days} å¤©ï¼‰\n")
        lines.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n")
        
        # ä»£ç å˜æ›´éƒ¨åˆ†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if include_code_changes:
            try:
                # è·å–å·¥ä½œç›®å½•ï¼ˆä» state_dir æ¨å¯¼ï¼‰
                workdir = self.state_dir.parent
                code_summary = generate_code_change_summary(
                    workdir,
                    since_days=since_days,
                    use_ai=use_ai_for_code,
                    llm_config=llm_config
                )
                lines.append("\n" + code_summary + "\n")
                lines.append("---\n")
            except Exception as e:
                print_info(f"ä»£ç å˜æ›´è¿½è¸ªè·³è¿‡: {e}")
        
        lines.append(f"\n**å®éªŒæ•°é‡**: {len(filtered)} ä¸ª\n")
        
        # ç»Ÿè®¡ï¼ˆå…¼å®¹ completed å’Œ succeededï¼‰
        completed = sum(1 for r in filtered if r.get('status') in ['completed', 'succeeded'])
        failed = sum(1 for r in filtered if r.get('status') == 'failed')
        
        lines.append(f"**å®Œæˆ**: {completed} ä¸ª | **å¤±è´¥**: {failed} ä¸ª\n")
        lines.append("\n---\n")
        
        # è¯¦ç»†åˆ—è¡¨
        lines.append("\n## å®éªŒåˆ—è¡¨\n")
        
        for i, run in enumerate(filtered, 1):
            name = run.get('name', 'unnamed')
            run_id = run.get('run_id', 'N/A')[:12]
            status = run.get('status', 'unknown')
            # ä¼˜å…ˆä½¿ç”¨ start_timeï¼Œfallback åˆ° ended_at
            start_time = run.get('start_time') or run.get('ended_at', 'N/A')
            primary_metric = run.get('primary_metric_value', 'N/A')
            
            status_emoji = "âœ…" if status in ['completed', 'succeeded'] else "âŒ" if status == "failed" else "â¸ï¸"
            
            lines.append(f"\n### {i}. {name} {status_emoji}\n")
            lines.append(f"- **ID**: `{run_id}`\n")
            lines.append(f"- **æ—¶é—´**: {start_time}\n")
            lines.append(f"- **çŠ¶æ€**: {status}\n")
            
            if primary_metric != 'N/A':
                metric_name = run.get('primary_metric', 'metric')
                lines.append(f"- **{metric_name}**: {primary_metric}\n")
            
            # å…ƒæ•°æ®
            metadata = run.get('metadata', {})
            if metadata:
                lines.append(f"- **é…ç½®**: {', '.join(f'{k}={v}' for k, v in metadata.items())}\n")
            
            # æŒ‡æ ‡
            metrics = run.get('metrics', {})
            if metrics:
                metrics_str = ', '.join(f'{k}={v:.4f}' if isinstance(v, float) else f'{k}={v}' 
                                       for k, v in metrics.items())
                lines.append(f"- **æŒ‡æ ‡**: {metrics_str}\n")
        
        # æœ€ä½³ç»“æœ
        if completed > 0:
            lines.append("\n---\n")
            lines.append("\n## æœ€ä½³ç»“æœ\n")
            
            completed_runs = [r for r in filtered if r.get('status') in ['completed', 'succeeded']]
            if completed_runs:
                # æ‰¾åˆ°æœ€ä½³
                best = max(
                    completed_runs, 
                    key=lambda r: r.get('primary_metric_value', float('-inf'))
                )
                
                lines.append(f"\n- **å®éªŒ**: {best.get('name')}\n")
                
                # æ™ºèƒ½æ˜¾ç¤ºæŒ‡æ ‡
                metric_name = best.get('primary_metric')
                metric_value = best.get('primary_metric_value')
                
                if metric_name and metric_value is not None:
                    # æœ‰ä¸»è¦æŒ‡æ ‡ï¼Œç›´æ¥æ˜¾ç¤º
                    lines.append(f"- **{metric_name}**: {metric_value}\n")
                else:
                    # æ²¡æœ‰ä¸»è¦æŒ‡æ ‡ï¼Œä» metrics ä¸­æ™ºèƒ½é€‰æ‹©
                    metrics = best.get('metrics', {})
                    if metrics:
                        # æŒ‰ä¼˜å…ˆçº§æŸ¥æ‰¾å¸¸è§æŒ‡æ ‡
                        for common_metric in ['accuracy', 'final_accuracy', 'f1_score', 'f1', 'auc', 'loss', 'final_loss']:
                            if common_metric in metrics:
                                value = metrics[common_metric]
                                if isinstance(value, float):
                                    lines.append(f"- **{common_metric}**: {value:.6f}\n")
                                else:
                                    lines.append(f"- **{common_metric}**: {value}\n")
                                break
                        else:
                            # æ²¡æœ‰å¸¸è§æŒ‡æ ‡ï¼Œæ˜¾ç¤ºç¬¬ä¸€ä¸ª
                            first_key = list(metrics.keys())[0]
                            value = metrics[first_key]
                            if isinstance(value, float):
                                lines.append(f"- **{first_key}**: {value:.6f}\n")
                            else:
                                lines.append(f"- **{first_key}**: {value}\n")
                
                best_metadata = best.get('metadata', {})
                if best_metadata:
                    lines.append(f"- **é…ç½®**: {', '.join(f'{k}={v}' for k, v in best_metadata.items())}\n")
        
        # AI ç”Ÿæˆçš„"æœ¬å‘¨æ¦‚è§ˆ"å’Œ"ä¸‹å‘¨è®¡åˆ’"ï¼ˆå¦‚æœå¯ç”¨ AIï¼‰
        if use_ai_for_code and llm_config and llm_config.get('llm_api_key'):
            lines.append("\n---\n")
            
            # åŠ¨æ€è°ƒæ•´æ ‡é¢˜
            if since_days == 1:
                overview_title = "ä»Šæ—¥å·¥ä½œæ¦‚è§ˆ"
            elif since_days >= 28:
                overview_title = "æœ¬æœˆå·¥ä½œæ¦‚è§ˆ"
            else:
                overview_title = "æœ¬å‘¨å·¥ä½œæ¦‚è§ˆ"
            
            lines.append(f"\n## ğŸ¯ {overview_title}\n")
            
            try:
                from .agent_llm import AgentsLLM
                from .code_tracker import CodeChangeTracker
                
                llm = AgentsLLM(
                    provider=llm_config.get('llm_provider'),
                    api_key=llm_config.get('llm_api_key'),
                    base_url=llm_config.get('llm_base_url'),
                    model=llm_config.get('llm_model'),
                    temperature=0.7
                )
                
                # æ„é€ è¯¦ç»†çš„å®éªŒä¸Šä¸‹æ–‡
                time_period = "ä»Šå¤©" if since_days == 1 else f"æœ€è¿‘ {since_days} å¤©"
                summary_context = f"## {time_period}å®éªŒæƒ…å†µ\n"
                summary_context += f"å®éªŒæ•°é‡ï¼š{len(filtered)} ä¸ªï¼ˆå®Œæˆ {completed} ä¸ªï¼Œå¤±è´¥ {failed} ä¸ªï¼‰\n"
                
                # è·å–æœ€ä½³ç»“æœå’ŒæŒ‡æ ‡
                if completed > 0:
                    # æ™ºèƒ½è·å–æœ€ä½³æŒ‡æ ‡
                    best_metric_name = best.get('primary_metric')
                    best_metric_value = best.get('primary_metric_value')
                    
                    if not best_metric_name or best_metric_value is None:
                        # ä» metrics ä¸­æ™ºèƒ½é€‰æ‹©
                        metrics = best.get('metrics', {})
                        for common in ['accuracy', 'final_accuracy', 'f1_score', 'f1', 'auc']:
                            if common in metrics:
                                best_metric_name = common
                                best_metric_value = metrics[common]
                                break
                    
                    if best_metric_name and best_metric_value is not None:
                        summary_context += f"\næœ€ä½³ç»“æœï¼š{best.get('name')} - {best_metric_name}={best_metric_value}\n"
                    else:
                        summary_context += f"\næœ€ä½³ç»“æœï¼š{best.get('name')}\n"
                
                # æ·»åŠ è¯¦ç»†çš„å®éªŒä¿¡æ¯ï¼ˆåŒ…æ‹¬å‚æ•°å’ŒæŒ‡æ ‡ï¼‰
                summary_context += "\nå®éªŒè¯¦æƒ…ï¼ˆå‰5ä¸ªï¼‰ï¼š\n"
                for i, run in enumerate(filtered[:5], 1):
                    summary_context += f"\n{i}. {run.get('name')} [{run.get('status')}]\n"
                    
                    # æ·»åŠ å®é™…çš„æŒ‡æ ‡ï¼ˆé‡è¦ï¼è®© AI çœ‹åˆ°çœŸå®æ•°æ®ï¼‰
                    metrics = run.get('metrics', {})
                    if metrics:
                        # ä¼˜å…ˆæ˜¾ç¤ºå¸¸è§æŒ‡æ ‡
                        important_metrics = {}
                        for key in ['accuracy', 'final_accuracy', 'loss', 'final_loss', 'f1_score', 'auc']:
                            if key in metrics:
                                important_metrics[key] = metrics[key]
                        
                        # å¦‚æœæœ‰é‡è¦æŒ‡æ ‡ï¼Œæ˜¾ç¤ºå®ƒä»¬
                        if important_metrics:
                            metric_str = ', '.join(f"{k}={v:.4f}" if isinstance(v, float) else f"{k}={v}" 
                                                  for k, v in important_metrics.items())
                            summary_context += f"   æŒ‡æ ‡: {metric_str}\n"
                        else:
                            # å¦åˆ™æ˜¾ç¤ºå‰3ä¸ªæŒ‡æ ‡
                            metric_str = ', '.join(f"{k}={v:.4f}" if isinstance(v, float) else f"{k}={v}" 
                                                  for k, v in list(metrics.items())[:3])
                            summary_context += f"   æŒ‡æ ‡: {metric_str}\n"
                    
                    # æ·»åŠ å…³é”®å‚æ•°
                    metadata = run.get('metadata', {})
                    if metadata:
                        param_str = ', '.join(f"{k}={v}" for k, v in list(metadata.items())[:3])
                        summary_context += f"   å‚æ•°: {param_str}\n"
                
                # å¦‚æœæœ‰å¤šä¸ªå®Œæˆçš„å®éªŒï¼Œæ·»åŠ å…³é”®æŒ‡æ ‡å¯¹æ¯”
                if completed > 1:
                    completed_runs = [r for r in filtered if r.get('status') in ['completed', 'succeeded']][:5]
                    if completed_runs:
                        # æ‰¾å‡ºæ‰€æœ‰å®éªŒä¸­å­˜åœ¨çš„å¸¸è§æŒ‡æ ‡
                        summary_context += f"\nå…³é”®æŒ‡æ ‡å¯¹æ¯”ï¼š\n"
                        for metric_name in ['final_accuracy', 'accuracy', 'final_loss', 'loss']:
                            values = []
                            for run in completed_runs:
                                metrics = run.get('metrics', {})
                                if metric_name in metrics:
                                    values.append((run.get('name'), metrics[metric_name]))
                            
                            if values:
                                summary_context += f"\n{metric_name}:\n"
                                for name, value in values[:3]:
                                    val_str = f"{value:.4f}" if isinstance(value, float) else str(value)
                                    summary_context += f"  - {name}: {val_str}\n"
                                break  # åªæ˜¾ç¤ºç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„å…³é”®æŒ‡æ ‡
                
                # æ·»åŠ ä»£ç å˜æ›´ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
                if include_code_changes:
                    workdir = self.state_dir.parent
                    tracker = CodeChangeTracker(workdir)
                    git_changes = tracker.get_git_changes(since_days)
                    
                    if git_changes and git_changes['has_changes']:
                        summary_context += f"\n## ä»£ç å˜æ›´æƒ…å†µ\n"
                        summary_context += f"æäº¤æ•°é‡ï¼š{len(git_changes['commits'])} ä¸ª\n"
                        summary_context += "æäº¤ä¿¡æ¯ï¼š\n"
                        for commit in git_changes['commits'][:5]:
                            summary_context += f"- {commit['message']}\n"
                        
                        if git_changes['changed_files']:
                            summary_context += "\nä¿®æ”¹çš„æ–‡ä»¶ç±»å‹ï¼š\n"
                            for cat_info in git_changes['changed_files'][:3]:
                                summary_context += f"- {cat_info['category']}: {len(cat_info['files'])} ä¸ªæ–‡ä»¶\n"
                
                # æ ¹æ®æ—¶é—´èŒƒå›´è°ƒæ•´æç¤ºè¯
                time_comparison = "ä»Šå¤©ç›¸æ¯”æ˜¨å¤©" if since_days == 1 else (
                    "æœ¬æœˆç›¸æ¯”ä¸Šæœˆ" if since_days >= 28 else "æœ¬å‘¨ç›¸æ¯”ä¸Šå‘¨"
                )
                
                if include_code_changes and git_changes and git_changes['has_changes']:
                    overview_prompt = f"è¯·ç”¨ 2-3 å¥è¯æ€»ç»“{time_comparison}çš„å·¥ä½œè¿›å±•å’Œå…³é”®æˆæœï¼ˆåŒ…æ‹¬ä»£ç æ”¹è¿›å’Œå®éªŒç»“æœï¼‰ï¼š"
                else:
                    overview_prompt = f"è¯·ç”¨ 2-3 å¥è¯æ€»ç»“{time_comparison}çš„å·¥ä½œè¿›å±•å’Œå…³é”®æˆæœï¼š"
                
                messages = [
                    {
                        "role": "system",
                        "content": """ä½ æ˜¯å®éªŒæ•°æ®åˆ†æä¸“å®¶ã€‚**ä¸¥æ ¼è¦æ±‚**ï¼š
1. å¿…é¡»è¯¦ç»†åˆ†ææä¾›çš„å®é™…æŒ‡æ ‡æ•°æ®ï¼ˆaccuracy, lossç­‰ï¼‰
2. å¿…é¡»å¯¹æ¯”ä¸åŒå®éªŒçš„é…ç½®å’Œæ•ˆæœ
3. å¼•ç”¨å…·ä½“æ•°å€¼å¿…é¡»æ¥è‡ªæä¾›çš„æ•°æ®ï¼Œä¸è¦ç¼–é€ 
4. å¦‚æœçœ‹åˆ°å¤šç»„å®éªŒï¼Œåˆ†æå‚æ•°å¯¹ç»“æœçš„å½±å“"""
                    },
                    {
                        "role": "user",
                        "content": f"""{overview_prompt}

**å®é™…æ•°æ®**ï¼š
{summary_context}

**æ€»ç»“è¦æ±‚**ï¼ˆ200-300å­—ï¼Œ3-4æ®µï¼‰ï¼š

**ç¬¬1æ®µï¼šæ•´ä½“æ¦‚å†µ**
- å®éªŒæ•°é‡ã€å®Œæˆ/å¤±è´¥æƒ…å†µ
- æœ€ä½³ç»“æœåŠå…¶é…ç½®ï¼ˆå¼•ç”¨å®é™…æŒ‡æ ‡å€¼ï¼‰

**ç¬¬2æ®µï¼šå‚æ•°å½±å“åˆ†æ**
- åˆ†æä¸åŒå‚æ•°é…ç½®å¯¹ç»“æœçš„å½±å“
- å¯¹æ¯”å…·ä½“å®éªŒï¼ˆå¦‚"å®éªŒXï¼ˆlr=Aï¼‰å¾—åˆ°accuracy=Bï¼Œå®éªŒYï¼ˆlr=Cï¼‰å¾—åˆ°accuracy=D"ï¼‰
- æ‰¾å‡ºè§„å¾‹æˆ–è¶‹åŠ¿

**ç¬¬3æ®µï¼šå…³é”®å‘ç°**
- å“ªäº›å‚æ•°é…ç½®æ•ˆæœå¥½
- å“ªäº›å‚æ•°é…ç½®æ•ˆæœå·®
- æœ€ä¼˜é…ç½®çš„ç‰¹å¾

**å¿…é¡»åšåˆ°**ï¼š
- âœ… å¼•ç”¨è‡³å°‘3ä¸ªå…·ä½“çš„æŒ‡æ ‡æ•°å€¼
- âœ… å¯¹æ¯”è‡³å°‘2ç»„å®éªŒ
- âœ… åˆ†æå‚æ•°å¯¹ç»“æœçš„å½±å“
- âœ… æŒ‡å‡ºæœ€ä½³å’Œæœ€å·®é…ç½®

**ç¦æ­¢**ï¼š
- âŒ è¯´"æ‰€æœ‰å®éªŒå‡ä¸ºhack"è¿™ç§æ— æ„ä¹‰çš„è¯
- âŒ è¯´"ç¼ºä¹æ•°æ®æ— æ³•åˆ†æ"ï¼ˆæ•°æ®å·²æä¾›ï¼‰
- âŒ ç¼–é€ æœªå‡ºç°çš„æ•°å­—
- âŒ åªè¯´"å®Œæˆäº†Xä¸ªå®éªŒ"è€Œä¸åˆ†æç»“æœ

è¯·ç”¨3-4ä¸ªè‡ªç„¶æ®µè¯¦ç»†æ€»ç»“ï¼š"""
                    }
                ]
                
                overview_chunks = []
                for chunk in llm.think(messages, temperature=0.7):
                    overview_chunks.append(chunk)
                
                lines.append("".join(overview_chunks) + "\n")
                
                # ç”Ÿæˆä¸‹å‘¨/æ˜æ—¥/ä¸‹æœˆè®¡åˆ’ï¼ˆæ ¹æ®æ—¶é—´èŒƒå›´ï¼‰
                if since_days == 1:
                    next_period = "æ˜å¤©"
                elif since_days >= 28:  # æœˆåº¦æŠ¥å‘Š
                    next_period = "ä¸‹æœˆ"
                else:  # å‘¨æŠ¥æˆ–å…¶ä»–
                    next_period = "ä¸‹å‘¨"
                
                lines.append(f"\n## ğŸ“‹ {next_period}è®¡åˆ’å»ºè®®\n")
                
                plan_prompt = f"æ ¹æ®ä»¥ä¸‹å®éªŒæƒ…å†µï¼Œè¯·ç»™å‡º 3 æ¡å…·ä½“çš„{next_period}å·¥ä½œå»ºè®®ï¼ˆæ¯æ¡ä¸€å¥è¯ï¼‰ï¼š"
                
                plan_messages = [
                    {
                        "role": "system",
                        "content": """ä½ æ˜¯å®éªŒè§„åˆ’åŠ©æ‰‹ã€‚**ä¸¥æ ¼è¦æ±‚**ï¼š
1. å»ºè®®å¿…é¡»åŸºäºå®é™…å®éªŒç»“æœå’Œå‚æ•°é…ç½®
2. åˆ†æå“ªäº›å‚æ•°æœ‰æ•ˆã€å“ªäº›æ— æ•ˆï¼Œé’ˆå¯¹æ€§æå‡ºæ”¹è¿›
3. ç»™å‡ºå…·ä½“çš„å‚æ•°å€¼èŒƒå›´å»ºè®®
4. å»ºè®®è¦å…·ä½“ã€å¯æ‰§è¡Œã€æœ‰æ˜ç¡®ç›®æ ‡"""
                    },
                    {
                        "role": "user",
                        "content": f"""{plan_prompt}

**å®é™…æ•°æ®**ï¼š
{summary_context}

**å»ºè®®è¦æ±‚**ï¼ˆ3-5æ¡ï¼‰ï¼š

**åŸºäºä»¥ä¸‹åˆ†ææå‡ºå»ºè®®**ï¼š
1. å“ªäº›å‚æ•°é…ç½®æ•ˆæœå¥½ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ
2. å“ªäº›å‚æ•°é…ç½®æ•ˆæœå·®ï¼Ÿåº”è¯¥é¿å…ä»€ä¹ˆï¼Ÿ
3. è¿˜æœ‰å“ªäº›å‚æ•°èŒƒå›´å€¼å¾—å°è¯•ï¼Ÿ
4. å¦‚ä½•åœ¨æœ€ä½³é…ç½®é™„è¿‘è¿›ä¸€æ­¥ä¼˜åŒ–ï¼Ÿ

**æ ¼å¼è¦æ±‚**ï¼š
- æ¯æ¡å»ºè®®åŒ…å«ï¼šå…·ä½“åŠ¨ä½œ + å…·ä½“å‚æ•°å€¼ + é¢„æœŸç›®æ ‡
- ä¾‹å¦‚ï¼š"æµ‹è¯• batch_size=128ï¼ˆå½“å‰æœ€ä½³64çš„2å€ï¼‰ï¼ŒéªŒè¯æ˜¯å¦èƒ½è¿›ä¸€æ­¥æå‡ final_accuracy"
- ä¾‹å¦‚ï¼š"é™ä½ lr è‡³ 0.005-0.01 èŒƒå›´ï¼ˆå½“å‰0.09è¿‡å¤§ï¼‰ï¼Œå‡å°‘è®­ç»ƒä¸ç¨³å®šæ€§"

**å¿…é¡»åšåˆ°**ï¼š
- âœ… å¼•ç”¨å®é™…å°è¯•è¿‡çš„å‚æ•°å€¼
- âœ… åŸºäºå®éªŒç»“æœç»™å‡ºé’ˆå¯¹æ€§å»ºè®®
- âœ… è¯´æ˜ä¸ºä»€ä¹ˆè¿™æ ·è°ƒæ•´ï¼ˆåŸºäºè§‚å¯Ÿåˆ°çš„ç°è±¡ï¼‰
- âœ… ç»™å‡ºå…·ä½“çš„æ•°å€¼å»ºè®®

**ç¦æ­¢**ï¼š
- âŒ å»ºè®®"åœ¨hackå‚æ•°é™„è¿‘æœç´¢"è¿™ç§æ— æ„ä¹‰çš„è¯
- âŒ è¯´"æµ‹è¯•hackçš„è½»å¾®æ‰°åŠ¨"
- âŒ ä¸åŸºäºå®é™…ç»“æœçš„ç©ºæ³›å»ºè®®

è¯·ç”¨bullet listæ ¼å¼è¾“å‡ºï¼ˆ3-5æ¡å…·ä½“å»ºè®®ï¼‰ï¼š"""
                    }
                ]
                
                plan_chunks = []
                for chunk in llm.think(plan_messages, temperature=0.8):
                    plan_chunks.append(chunk)
                
                lines.append("".join(plan_chunks) + "\n")
                
            except Exception as e:
                lines.append(f"*AI æ€»ç»“ç”Ÿæˆå¤±è´¥: {e}*\n")
        
        return "".join(lines)
    
    def generate_table(
        self,
        name_pattern: Optional[str] = None,
        columns: Optional[List[str]] = None,
        format: str = 'markdown'
    ) -> str:
        """
        ç”Ÿæˆæ¶ˆèè¡¨æ ¼
        
        Args:
            name_pattern: åç§°ç­›é€‰ï¼ˆå¦‚ 'ablation_'ï¼‰
            columns: è¦æ˜¾ç¤ºçš„åˆ—ï¼ˆå…ƒæ•°æ®é”®æˆ–æŒ‡æ ‡é”®ï¼‰
            format: è¾“å‡ºæ ¼å¼ ('markdown' æˆ– 'latex')
            
        Returns:
            è¡¨æ ¼å­—ç¬¦ä¸²
        """
        runs = self.load_history()
        
        # ç­›é€‰
        filtered = self.filter_runs(runs, name_pattern=name_pattern)
        
        if not filtered:
            return "æ²¡æœ‰åŒ¹é…çš„å®éªŒè®°å½•ã€‚\n"
        
        # è‡ªåŠ¨æ£€æµ‹åˆ—ï¼ˆå¦‚æœæœªæŒ‡å®šï¼‰
        if not columns:
            # æ”¶é›†æ‰€æœ‰å…ƒæ•°æ®å’ŒæŒ‡æ ‡çš„é”®
            all_keys = set()
            for run in filtered:
                all_keys.update(run.get('metadata', {}).keys())
                all_keys.update(run.get('metrics', {}).keys())
            columns = sorted(all_keys)
        
        # ç”Ÿæˆè¡¨æ ¼
        if format == 'latex':
            return self._generate_latex_table(filtered, columns)
        else:
            return self._generate_markdown_table(filtered, columns)
    
    def _generate_markdown_table(
        self,
        runs: List[Dict[str, Any]],
        columns: List[str]
    ) -> str:
        """ç”Ÿæˆ Markdown è¡¨æ ¼"""
        lines = []
        
        # è¡¨å¤´
        header = ['å®éªŒåç§°'] + columns
        lines.append('| ' + ' | '.join(header) + ' |')
        lines.append('|' + '|'.join(['---'] * len(header)) + '|')
        
        # æ•°æ®è¡Œ
        for run in runs:
            name = run.get('name', 'unnamed')
            metadata = run.get('metadata', {})
            metrics = run.get('metrics', {})
            
            row = [name]
            for col in columns:
                # å…ˆä»å…ƒæ•°æ®æ‰¾ï¼Œå†ä»æŒ‡æ ‡æ‰¾
                value = metadata.get(col) or metrics.get(col, '-')
                if isinstance(value, float):
                    value = f"{value:.4f}"
                row.append(str(value))
            
            lines.append('| ' + ' | '.join(row) + ' |')
        
        return '\n'.join(lines)
    
    def _generate_latex_table(
        self,
        runs: List[Dict[str, Any]],
        columns: List[str]
    ) -> str:
        """ç”Ÿæˆ LaTeX è¡¨æ ¼"""
        lines = []
        
        # è¡¨æ ¼å¼€å§‹
        col_format = 'l' + 'c' * len(columns)
        lines.append('\\begin{table}[h]')
        lines.append('\\centering')
        lines.append(f'\\begin{{tabular}}{{{col_format}}}')
        lines.append('\\hline')
        
        # è¡¨å¤´
        header = ['å®éªŒåç§°'] + columns
        lines.append(' & '.join(header) + ' \\\\')
        lines.append('\\hline')
        
        # æ•°æ®è¡Œ
        for run in runs:
            name = run.get('name', 'unnamed').replace('_', '\\_')
            metadata = run.get('metadata', {})
            metrics = run.get('metrics', {})
            
            row = [name]
            for col in columns:
                value = metadata.get(col) or metrics.get(col, '-')
                if isinstance(value, float):
                    value = f"{value:.4f}"
                row.append(str(value))
            
            lines.append(' & '.join(row) + ' \\\\')
        
        lines.append('\\hline')
        lines.append('\\end{tabular}')
        lines.append('\\caption{å®éªŒç»“æœå¯¹æ¯”}')
        lines.append('\\label{tab:results}')
        lines.append('\\end{table}')
        
        return '\n'.join(lines)


def export_summary(
    state_dir: Path,
    since_days: int = 7,
    name_pattern: Optional[str] = None,
    output_file: Optional[Path] = None,
    include_code_changes: bool = True,
    use_ai_for_code: bool = False,
    llm_config: Optional[Dict[str, Any]] = None
) -> str:
    """
    å¯¼å‡ºå®éªŒæ‘˜è¦
    
    Args:
        state_dir: çŠ¶æ€ç›®å½•
        since_days: æœ€è¿‘å‡ å¤©
        name_pattern: åç§°ç­›é€‰
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        
    Returns:
        æ‘˜è¦å†…å®¹
    """
    exporter = ExperimentExporter(state_dir)
    summary = exporter.generate_summary(
        since_days,
        name_pattern,
        include_code_changes=include_code_changes,
        use_ai_for_code=use_ai_for_code,
        llm_config=llm_config
    )
    
    if output_file:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(summary)
        print_success(f"æ‘˜è¦å·²ä¿å­˜åˆ°: {output_file}")
    
    return summary


def export_table(
    state_dir: Path,
    name_pattern: Optional[str] = None,
    columns: Optional[List[str]] = None,
    format: str = 'markdown',
    output_file: Optional[Path] = None
) -> str:
    """
    å¯¼å‡ºæ¶ˆèè¡¨æ ¼
    
    Args:
        state_dir: çŠ¶æ€ç›®å½•
        name_pattern: åç§°ç­›é€‰
        columns: åˆ—ååˆ—è¡¨
        format: è¾“å‡ºæ ¼å¼
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        
    Returns:
        è¡¨æ ¼å†…å®¹
    """
    exporter = ExperimentExporter(state_dir)
    table = exporter.generate_table(name_pattern, columns, format)
    
    if output_file:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(table)
        print_success(f"è¡¨æ ¼å·²ä¿å­˜åˆ°: {output_file}")
    
    return table

