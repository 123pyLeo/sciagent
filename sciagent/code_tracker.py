"""ä»£ç å˜æ›´è¿½è¸ªæ¨¡å— - ç”¨äºç”Ÿæˆå‘¨æŠ¥ä¸­çš„ä»£ç å˜æ›´æ‘˜è¦"""

from __future__ import annotations

import os
import subprocess
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple

from .ui import print_info, print_warning, print_error


class CodeChangeTracker:
    """ä»£ç å˜æ›´è¿½è¸ªå™¨"""
    
    def __init__(self, workdir: Path):
        """
        åˆå§‹åŒ–è¿½è¸ªå™¨
        
        Args:
            workdir: å·¥ä½œç›®å½•
        """
        self.workdir = workdir
        self.is_git_repo = self._check_git()
    
    def _check_git(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯ Git ä»“åº“"""
        git_dir = self.workdir / ".git"
        return git_dir.exists() and git_dir.is_dir()
    
    def get_git_changes(self, since_days: int = 7) -> Optional[Dict]:
        """
        è·å– Git å˜æ›´è®°å½•
        
        Args:
            since_days: ç»Ÿè®¡æœ€è¿‘å‡ å¤©
            
        Returns:
            å˜æ›´ä¿¡æ¯å­—å…¸ï¼Œå¦‚æœä¸æ˜¯ Git ä»“åº“åˆ™è¿”å› None
        """
        if not self.is_git_repo:
            return None
        
        since_date = datetime.now() - timedelta(days=since_days)
        since_str = since_date.strftime('%Y-%m-%d')
        
        try:
            # è·å–æäº¤è®°å½•
            commits = self._get_commits(since_str)
            
            # è·å–æ–‡ä»¶å˜æ›´ç»Ÿè®¡
            file_stats = self._get_file_stats(since_str)
            
            # è·å–ä¿®æ”¹çš„æ–‡ä»¶åˆ—è¡¨
            changed_files = self._get_changed_files(since_str)
            
            return {
                'commits': commits,
                'file_stats': file_stats,
                'changed_files': changed_files,
                'has_changes': len(commits) > 0
            }
            
        except Exception as e:
            print_warning(f"è·å– Git å˜æ›´å¤±è´¥: {e}")
            return None
    
    def _get_commits(self, since_date: str) -> List[Dict]:
        """è·å–æäº¤è®°å½•"""
        try:
            result = subprocess.run(
                ['git', 'log', f'--since={since_date}', 
                 '--pretty=format:%H|%an|%ad|%s', '--date=short'],
                cwd=self.workdir,
                capture_output=True,
                text=True,
                timeout=5
            )
            
            if result.returncode != 0:
                return []
            
            commits = []
            for line in result.stdout.strip().split('\n'):
                if not line:
                    continue
                parts = line.split('|', 3)
                if len(parts) == 4:
                    commits.append({
                        'hash': parts[0][:8],
                        'author': parts[1],
                        'date': parts[2],
                        'message': parts[3]
                    })
            
            return commits
            
        except Exception:
            return []
    
    def _get_file_stats(self, since_date: str) -> Dict[str, int]:
        """è·å–æ–‡ä»¶å˜æ›´ç»Ÿè®¡"""
        try:
            result = subprocess.run(
                ['git', 'diff', f'--since={since_date}', 
                 '--numstat', 'HEAD~1', 'HEAD'],
                cwd=self.workdir,
                capture_output=True,
                text=True,
                timeout=5
            )
            
            total_additions = 0
            total_deletions = 0
            
            for line in result.stdout.strip().split('\n'):
                if not line:
                    continue
                parts = line.split('\t')
                if len(parts) >= 2:
                    try:
                        additions = int(parts[0]) if parts[0] != '-' else 0
                        deletions = int(parts[1]) if parts[1] != '-' else 0
                        total_additions += additions
                        total_deletions += deletions
                    except ValueError:
                        continue
            
            return {
                'additions': total_additions,
                'deletions': total_deletions,
                'total': total_additions + total_deletions
            }
            
        except Exception:
            return {'additions': 0, 'deletions': 0, 'total': 0}
    
    def _get_changed_files(self, since_date: str) -> List[str]:
        """è·å–å˜æ›´çš„æ–‡ä»¶åˆ—è¡¨"""
        try:
            result = subprocess.run(
                ['git', 'diff', f'--since={since_date}', 
                 '--name-only', 'HEAD~1', 'HEAD'],
                cwd=self.workdir,
                capture_output=True,
                text=True,
                timeout=5
            )
            
            files = [f for f in result.stdout.strip().split('\n') if f]
            
            # æŒ‰æ–‡ä»¶ç±»å‹åˆ†ç±»
            categorized = self._categorize_files(files)
            
            return categorized
            
        except Exception:
            return []
    
    def _categorize_files(self, files: List[str]) -> List[Dict]:
        """
        æŒ‰æ–‡ä»¶ç±»å‹åˆ†ç±»
        
        Args:
            files: æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            
        Returns:
            åˆ†ç±»åçš„æ–‡ä»¶ä¿¡æ¯
        """
        categories = {
            'model': [],      # æ¨¡å‹ç›¸å…³
            'data': [],       # æ•°æ®å¤„ç†
            'loss': [],       # æŸå¤±å‡½æ•°
            'train': [],      # è®­ç»ƒè„šæœ¬
            'config': [],     # é…ç½®æ–‡ä»¶
            'other': []       # å…¶ä»–
        }
        
        for file in files:
            file_lower = file.lower()
            
            # åˆ†ç±»é€»è¾‘
            if any(k in file_lower for k in ['model', 'net', 'arch']):
                categories['model'].append(file)
            elif any(k in file_lower for k in ['data', 'dataset', 'loader']):
                categories['data'].append(file)
            elif any(k in file_lower for k in ['loss', 'criterion']):
                categories['loss'].append(file)
            elif any(k in file_lower for k in ['train', 'main']):
                categories['train'].append(file)
            elif any(k in file_lower for k in ['config', 'yaml', 'json', '.cfg']):
                categories['config'].append(file)
            else:
                categories['other'].append(file)
        
        # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
        result = []
        for category, file_list in categories.items():
            if file_list:
                result.append({
                    'category': category,
                    'files': file_list
                })
        
        return result
    
    def get_file_changes_by_mtime(
        self,
        since_days: int = 7,
        extensions: Optional[List[str]] = None
    ) -> List[Dict]:
        """
        é€šè¿‡æ–‡ä»¶ä¿®æ”¹æ—¶é—´è·å–å˜æ›´ï¼ˆä¸ä¾èµ– Gitï¼‰
        
        Args:
            since_days: ç»Ÿè®¡æœ€è¿‘å‡ å¤©
            extensions: è¦æ£€æŸ¥çš„æ–‡ä»¶æ‰©å±•åï¼ˆå¦‚ ['.py', '.yaml']ï¼‰
            
        Returns:
            å˜æ›´çš„æ–‡ä»¶åˆ—è¡¨
        """
        if extensions is None:
            extensions = ['.py', '.yaml', '.yml', '.json', '.toml', '.sh']
        
        since_time = datetime.now() - timedelta(days=since_days)
        changed_files = []
        
        try:
            # éå†å·¥ä½œç›®å½•
            for root, dirs, files in os.walk(self.workdir):
                # è·³è¿‡éšè—ç›®å½•ã€è™šæ‹Ÿç¯å¢ƒã€æ„å»ºç›®å½•
                dirs[:] = [d for d in dirs if not d.startswith('.') 
                          and d not in [
                              'venv', 'env', 'light_env', 'virtualenv',  # è™šæ‹Ÿç¯å¢ƒ
                              '__pycache__', 'node_modules',              # ç¼“å­˜
                              'build', 'dist', '.egg-info',               # æ„å»ºç›®å½•
                          ]]
                
                for file in files:
                    file_path = Path(root) / file
                    
                    # æ£€æŸ¥æ‰©å±•å
                    if file_path.suffix not in extensions:
                        continue
                    
                    # æ£€æŸ¥ä¿®æ”¹æ—¶é—´
                    try:
                        mtime = datetime.fromtimestamp(file_path.stat().st_mtime)
                        if mtime >= since_time:
                            rel_path = file_path.relative_to(self.workdir)
                            changed_files.append({
                                'path': str(rel_path),
                                'mtime': mtime.strftime('%Y-%m-%d %H:%M'),
                                'size': file_path.stat().st_size
                            })
                    except Exception:
                        continue
            
            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
            changed_files.sort(key=lambda x: x['mtime'], reverse=True)
            
            return changed_files
            
        except Exception as e:
            print_error(f"è·å–æ–‡ä»¶å˜æ›´å¤±è´¥: {e}")
            return []
    
    def get_code_diff_summary(self, since_days: int = 7) -> Optional[str]:
        """
        è·å–ä»£ç å·®å¼‚æ‘˜è¦ï¼ˆç”¨äº AI åˆ†æï¼‰
        
        Args:
            since_days: ç»Ÿè®¡æœ€è¿‘å‡ å¤©
            
        Returns:
            å·®å¼‚æ‘˜è¦æ–‡æœ¬
        """
        if not self.is_git_repo:
            return None
        
        since_date = datetime.now() - timedelta(days=since_days)
        since_str = since_date.strftime('%Y-%m-%d')
        
        try:
            # è·å–ç®€è¦çš„ diff ç»Ÿè®¡
            result = subprocess.run(
                ['git', 'diff', f'--since={since_date}', '--stat', 'HEAD~1', 'HEAD'],
                cwd=self.workdir,
                capture_output=True,
                text=True,
                timeout=10
            )
            
            if result.returncode == 0 and result.stdout.strip():
                return result.stdout.strip()
            
            # å¦‚æœä¸Šé¢å¤±è´¥ï¼Œå°è¯•è·å–æäº¤ä¿¡æ¯
            result = subprocess.run(
                ['git', 'log', f'--since={since_str}', 
                 '--pretty=format:%s', '--no-merges'],
                cwd=self.workdir,
                capture_output=True,
                text=True,
                timeout=5
            )
            
            if result.returncode == 0 and result.stdout.strip():
                messages = result.stdout.strip().split('\n')
                return '\n'.join(f"- {msg}" for msg in messages if msg)
            
            return None
            
        except Exception:
            return None


def generate_code_change_summary(
    workdir: Path,
    since_days: int = 7,
    use_ai: bool = False,
    llm_config: Optional[Dict] = None
) -> str:
    """
    ç”Ÿæˆä»£ç å˜æ›´æ‘˜è¦
    
    Args:
        workdir: å·¥ä½œç›®å½•
        since_days: ç»Ÿè®¡æœ€è¿‘å‡ å¤©
        use_ai: æ˜¯å¦ä½¿ç”¨ AI æ€»ç»“
        llm_config: LLM é…ç½®
        
    Returns:
        Markdown æ ¼å¼çš„ä»£ç å˜æ›´æ‘˜è¦
    """
    tracker = CodeChangeTracker(workdir)
    lines = []
    
    lines.append(f"## ğŸ“ ä»£ç å˜æ›´ï¼ˆæœ€è¿‘ {since_days} å¤©ï¼‰\n")
    
    # å°è¯•ä½¿ç”¨ Git
    git_changes = tracker.get_git_changes(since_days)
    
    if git_changes and git_changes['has_changes']:
        # Git ä»“åº“ä¸”æœ‰å˜æ›´
        commits = git_changes['commits']
        file_stats = git_changes['file_stats']
        changed_files = git_changes['changed_files']
        
        lines.append(f"**æäº¤æ•°é‡**: {len(commits)} ä¸ª\n")
        
        if file_stats['total'] > 0:
            lines.append(
                f"**ä»£ç å˜æ›´**: +{file_stats['additions']} "
                f"-{file_stats['deletions']} è¡Œ\n"
            )
        
        lines.append("\n### æäº¤è®°å½•\n")
        for commit in commits[:10]:  # æœ€å¤šæ˜¾ç¤º 10 ä¸ª
            lines.append(
                f"- `{commit['hash']}` [{commit['date']}] "
                f"{commit['message']}\n"
            )
        
        if changed_files:
            lines.append("\n### ä¿®æ”¹çš„æ–‡ä»¶\n")
            for cat_info in changed_files:
                category = cat_info['category']
                files = cat_info['files']
                
                category_names = {
                    'model': 'æ¨¡å‹æ¶æ„',
                    'data': 'æ•°æ®å¤„ç†',
                    'loss': 'æŸå¤±å‡½æ•°',
                    'train': 'è®­ç»ƒè„šæœ¬',
                    'config': 'é…ç½®æ–‡ä»¶',
                    'other': 'å…¶ä»–'
                }
                
                lines.append(f"\n**{category_names.get(category, category)}**:\n")
                for file in files[:5]:  # æ¯ç±»æœ€å¤š5ä¸ª
                    lines.append(f"- `{file}`\n")
        
        # å¦‚æœå¯ç”¨ AIï¼Œç”Ÿæˆä»£ç å˜æ›´æ€»ç»“
        if use_ai and llm_config and llm_config.get('llm_api_key'):
            lines.append("\n### ğŸ¤– ä»£ç å˜æ›´æ€»ç»“\n")
            
            # æ„å»ºæ›´ä¸°å¯Œçš„ä¸Šä¸‹æ–‡
            context_parts = []
            context_parts.append(f"æäº¤æ•°é‡: {len(commits)}")
            
            if commits:
                context_parts.append("\næäº¤ä¿¡æ¯:")
                for commit in commits[:5]:  # å‰5ä¸ªæäº¤
                    context_parts.append(f"- {commit['message']}")
            
            if changed_files:
                context_parts.append("\nä¿®æ”¹çš„æ–‡ä»¶:")
                for cat_info in changed_files[:3]:  # å‰3ä¸ªåˆ†ç±»
                    category = cat_info['category']
                    files = cat_info['files'][:3]  # æ¯ä¸ªåˆ†ç±»å‰3ä¸ªæ–‡ä»¶
                    context_parts.append(f"- {category}: {', '.join(files)}")
            
            change_context = '\n'.join(context_parts)
            
            try:
                from .agent_llm import AgentsLLM
                
                llm = AgentsLLM(
                    provider=llm_config.get('llm_provider'),
                    api_key=llm_config.get('llm_api_key'),
                    base_url=llm_config.get('llm_base_url'),
                    model=llm_config.get('llm_model'),
                    temperature=0.7
                )
                
                # æ ¹æ®æ—¶é—´èŒƒå›´è°ƒæ•´æç¤ºè¯
                time_context = "æ˜¨å¤©ç›¸æ¯”å‰å¤©" if since_days == 1 else (
                    "æœ¬æœˆç›¸æ¯”ä¸Šæœˆ" if since_days >= 28 else "æœ¬å‘¨ç›¸æ¯”ä¸Šå‘¨"
                )
                
                messages = [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯ Leaderï¼Œéœ€è¦å®¡æŸ¥ä»£ç æäº¤å¹¶ç»™å‡ºå…·ä½“çš„æŠ€æœ¯ç»†èŠ‚æ€»ç»“ï¼Œç”¨äºå›¢é˜Ÿæ±‡æŠ¥å’ŒæŠ€æœ¯å¤ç›˜ã€‚é¿å…ç©ºè¯å¥—è¯ï¼Œè¦å…·ä½“ã€å¯æ‰§è¡Œã€æœ‰æŠ€æœ¯æ·±åº¦ã€‚"
                    },
                    {
                        "role": "user",
                        "content": f"è¯·æ€»ç»“{time_context}çš„ä»£ç æ”¹è¿›ï¼ˆ3-5 æ¡è¦ç‚¹ï¼Œæ¯æ¡å…·ä½“è¯´æ˜æŠ€æœ¯å®ç°ï¼‰ï¼š\n\n{change_context}\n\nè¦æ±‚ï¼š\n1. å…·ä½“è¯´æ˜æ”¹äº†å“ªäº›æ–‡ä»¶çš„ä»€ä¹ˆåŠŸèƒ½ï¼ˆä¸è¦æ³›æ³›è€Œè°ˆï¼‰\n2. å…³é”®æŠ€æœ¯ç‚¹ï¼šç”¨äº†ä»€ä¹ˆæŠ€æœ¯/æ¡†æ¶/ç®—æ³•/è®¾è®¡æ¨¡å¼\n3. è§£å†³äº†ä»€ä¹ˆå…·ä½“é—®é¢˜ï¼ˆè¦æœ‰å®é™…åœºæ™¯ï¼Œä¸æ˜¯'æå‡æ€§èƒ½'è¿™ç§ç©ºè¯ï¼‰\n4. å¦‚æœæ˜¯é‡æ„ï¼Œè¯´æ˜å…·ä½“çš„é‡æ„æ‰‹æ®µï¼ˆå¦‚æŠ½è±¡ç±»/å·¥å‚æ¨¡å¼/ä¾èµ–æ³¨å…¥ï¼‰\n5. å¦‚æœæœ‰æ€§èƒ½ä¼˜åŒ–ï¼Œç»™å‡ºå…·ä½“æŒ‡æ ‡æˆ–æ”¹è¿›ç‚¹\n\nç¤ºä¾‹æ ¼å¼ï¼š\nâ€¢ æ¨¡å‹æ¶æ„ï¼šåœ¨ `model.py` ä¸­å¼•å…¥å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ›¿æ¢åŸæœ‰çš„ LSTM ç¼–ç å™¨\nâ€¢ æ•°æ®å¤„ç†ï¼š`dataloader.py` å¢åŠ åŠ¨æ€æ‰¹å¤„ç†ï¼Œå‡å°‘ 30% å†…å­˜å ç”¨\nâ€¢ è®­ç»ƒä¼˜åŒ–ï¼šå®ç°æ¢¯åº¦ç´¯ç§¯ï¼ˆaccumulation_steps=4ï¼‰ï¼Œæ”¯æŒå¤§ batch è®­ç»ƒ"
                    }
                ]
                
                summary_chunks = []
                for chunk in llm.think(messages, temperature=0.5):
                    summary_chunks.append(chunk)
                
                lines.append("".join(summary_chunks) + "\n")
                
            except Exception as e:
                lines.append(f"*AI æ€»ç»“å¤±è´¥: {e}*\n")
    
    else:
        # ä¸æ˜¯ Git ä»“åº“æˆ–æ— å˜æ›´ï¼Œä½¿ç”¨æ–‡ä»¶ä¿®æ”¹æ—¶é—´
        lines.append("*Git ä»“åº“æœªæ£€æµ‹åˆ°å˜æ›´ï¼Œä½¿ç”¨æ–‡ä»¶ä¿®æ”¹æ—¶é—´è¿½è¸ª*\n")
        
        file_changes = tracker.get_file_changes_by_mtime(since_days)
        
        if file_changes:
            lines.append(f"\n**ä¿®æ”¹/æ–°å¢çš„æ–‡ä»¶**: {len(file_changes)} ä¸ª\n")
            lines.append("\n### æœ€è¿‘ä¿®æ”¹çš„æ–‡ä»¶\n")
            
            for file_info in file_changes[:20]:  # æœ€å¤šæ˜¾ç¤º 20 ä¸ª
                lines.append(
                    f"- `{file_info['path']}` "
                    f"({file_info['mtime']})\n"
                )
            
            # å¦‚æœå¯ç”¨ AIï¼Œå¯¹æ–‡ä»¶ä¿®æ”¹ä¹Ÿè¿›è¡Œæ€»ç»“
            if use_ai and llm_config and llm_config.get('llm_api_key'):
                lines.append("\n### ğŸ¤– ä»£ç å˜æ›´æ€»ç»“\n")
                
                # æ„å»ºæ–‡ä»¶ä¿®æ”¹ä¸Šä¸‹æ–‡
                context_parts = []
                context_parts.append(f"ä¿®æ”¹/æ–°å¢æ–‡ä»¶æ•°é‡: {len(file_changes)}")
                context_parts.append("\nä¸»è¦ä¿®æ”¹çš„æ–‡ä»¶:")
                
                # æŒ‰æ–‡ä»¶ç±»å‹åˆ†ç±»
                file_by_type = {}
                for f in file_changes[:15]:  # å‰15ä¸ªæ–‡ä»¶
                    path = f['path']
                    file_lower = path.lower()
                    
                    # ç®€å•åˆ†ç±»
                    if any(k in file_lower for k in ['model', 'net', 'arch']):
                        file_type = 'æ¨¡å‹ç›¸å…³'
                    elif any(k in file_lower for k in ['data', 'dataset', 'loader']):
                        file_type = 'æ•°æ®å¤„ç†'
                    elif any(k in file_lower for k in ['train', 'main']):
                        file_type = 'è®­ç»ƒè„šæœ¬'
                    elif any(k in file_lower for k in ['config', 'yaml', 'json']):
                        file_type = 'é…ç½®æ–‡ä»¶'
                    else:
                        file_type = 'å…¶ä»–'
                    
                    if file_type not in file_by_type:
                        file_by_type[file_type] = []
                    file_by_type[file_type].append(path)
                
                for file_type, paths in file_by_type.items():
                    context_parts.append(f"- {file_type}: {', '.join(paths[:3])}")
                
                change_context = '\n'.join(context_parts)
                
                try:
                    from .agent_llm import AgentsLLM
                    
                    llm = AgentsLLM(
                        provider=llm_config.get('llm_provider'),
                        api_key=llm_config.get('llm_api_key'),
                        base_url=llm_config.get('llm_base_url'),
                        model=llm_config.get('llm_model'),
                        temperature=0.7
                    )
                    
                    # æ ¹æ®æ—¶é—´èŒƒå›´è°ƒæ•´æç¤ºè¯
                    time_context = "æ˜¨å¤©ç›¸æ¯”å‰å¤©" if since_days == 1 else (
                        "æœ¬æœˆç›¸æ¯”ä¸Šæœˆ" if since_days >= 28 else "æœ¬å‘¨ç›¸æ¯”ä¸Šå‘¨"
                    )
                    
                    messages = [
                        {
                            "role": "system",
                            "content": "ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯ Leaderï¼Œéœ€è¦å®¡æŸ¥ä»£ç å˜æ›´å¹¶ç»™å‡ºå…·ä½“çš„æŠ€æœ¯ç»†èŠ‚æ€»ç»“ï¼Œç”¨äºå›¢é˜Ÿæ±‡æŠ¥å’ŒæŠ€æœ¯å¤ç›˜ã€‚é¿å…ç©ºè¯å¥—è¯ï¼Œè¦å…·ä½“ã€å¯æ‰§è¡Œã€æœ‰æŠ€æœ¯æ·±åº¦ã€‚"
                        },
                        {
                            "role": "user",
                            "content": f"è¯·æ€»ç»“{time_context}çš„ä»£ç å·¥ä½œï¼ˆ3-5 æ¡è¦ç‚¹ï¼Œæ¯æ¡å…·ä½“è¯´æ˜æŠ€æœ¯å®ç°ï¼‰ï¼š\n\n{change_context}\n\nè¦æ±‚ï¼š\n1. å…·ä½“è¯´æ˜æ”¹äº†/æ–°å¢äº†å“ªäº›æ–‡ä»¶çš„ä»€ä¹ˆåŠŸèƒ½ï¼ˆä¸è¦æ³›æ³›è€Œè°ˆï¼‰\n2. å…³é”®æŠ€æœ¯ç‚¹ï¼šç”¨äº†ä»€ä¹ˆæŠ€æœ¯/æ¡†æ¶/ç®—æ³•\n3. è§£å†³äº†ä»€ä¹ˆå…·ä½“é—®é¢˜ï¼ˆä¸æ˜¯'æå‡å¯å¤ç°æ€§'è¿™ç§ç©ºè¯ï¼‰\n4. å¦‚æœæ˜¯é‡æ„ï¼Œè¯´æ˜å…·ä½“çš„é‡æ„æ‰‹æ®µ\n5. å¦‚æœæœ‰æ€§èƒ½ä¼˜åŒ–ï¼Œç»™å‡ºå…·ä½“æŒ‡æ ‡\n\nç¤ºä¾‹æ ¼å¼ï¼š\nâ€¢ æ–°å¢ `code_tracker.py` - å®ç°åŸºäº Git å’Œæ–‡ä»¶ mtime çš„åŒæ¨¡å¼å˜æ›´è¿½è¸ª\nâ€¢ é‡æ„ `exporter.py` - å¼•å…¥ ExperimentExporter ç±»ç»Ÿä¸€å†å²æ•°æ®å¯¼å‡ºæ¥å£\nâ€¢ ä¼˜åŒ– `cli.py` - å¢åŠ  daily/weekly/monthly å¿«æ·å‘½ä»¤ï¼Œå‡å°‘ç”¨æˆ·å‚æ•°è¾“å…¥"
                        }
                    ]
                    
                    summary_chunks = []
                    for chunk in llm.think(messages, temperature=0.5):
                        summary_chunks.append(chunk)
                    
                    lines.append("".join(summary_chunks) + "\n")
                    
                except Exception as e:
                    lines.append(f"*AI æ€»ç»“å¤±è´¥: {e}*\n")
        else:
            lines.append("\n*æœ€è¿‘æ²¡æœ‰ä»£ç å˜æ›´*\n")
    
    return "".join(lines)

