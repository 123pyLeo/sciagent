#!/usr/bin/env python3
"""
è¶…ç®€å•çš„è®­ç»ƒç¤ºä¾‹ - çº¿æ€§å›å½’

ä¸éœ€è¦é¢å¤–ä¾èµ–ï¼Œå‡ ç§’é’Ÿå°±èƒ½è·‘å®Œï¼Œç”¨äºå¿«é€Ÿæµ‹è¯• SciAgent
"""

import json
import random
import time
from pathlib import Path


def generate_data(n_samples=100):
    """ç”Ÿæˆç®€å•çš„çº¿æ€§å›å½’æ•°æ®"""
    # y = 2*x + 3 + noise
    X = [random.uniform(0, 10) for _ in range(n_samples)]
    y = [2 * x + 3 + random.gauss(0, 0.5) for x in X]
    return X, y


def train_linear_regression(X, y, learning_rate=0.05, epochs=100):
    """ç®€å•çš„çº¿æ€§å›å½’è®­ç»ƒï¼ˆæ¢¯åº¦ä¸‹é™ï¼‰"""
    # åˆå§‹åŒ–å‚æ•°
    w = random.uniform(-1, 1)
    b = random.uniform(-1, 1)
    
    n = len(X)
    
    print(f"ğŸš€ å¼€å§‹è®­ç»ƒçº¿æ€§å›å½’ (y = w*x + b)")
    print(f"  - æ ·æœ¬æ•°: {n}")
    print(f"  - å­¦ä¹ ç‡: {learning_rate}")
    print(f"  - è®­ç»ƒè½®æ•°: {epochs}")
    print()
    
    for epoch in range(1, epochs + 1):
        # å‰å‘ä¼ æ’­ï¼šè®¡ç®—é¢„æµ‹å€¼
        predictions = [w * x + b for x in X]
        
        # è®¡ç®—æŸå¤±ï¼ˆMSEï¼‰
        loss = sum((pred - true) ** 2 for pred, true in zip(predictions, y)) / n
        
        # åå‘ä¼ æ’­ï¼šè®¡ç®—æ¢¯åº¦
        grad_w = sum(2 * (pred - true) * x for pred, true, x in zip(predictions, y, X)) / n
        grad_b = sum(2 * (pred - true) for pred, true in zip(predictions, y)) / n
        
        # æ›´æ–°å‚æ•°
        w = w - learning_rate * grad_w
        b = b - learning_rate * grad_b
        
        # æ¯10è½®æ‰“å°ä¸€æ¬¡
        if epoch % 10 == 0 or epoch == 1:
            print(f"Epoch {epoch:3d}/{epochs} - loss: {loss:.6f}, w: {w:.4f}, b: {b:.4f}")
        
        # ä¿å­˜æŒ‡æ ‡
        metrics = {
            "epoch": epoch,
            "train_loss": loss,
            "w": w,
            "b": b,
            "learning_rate": learning_rate
        }
        
        with open("metrics.json", "w") as f:
            json.dump(metrics, f, indent=2)
        
        # ç¨å¾®å»¶è¿Ÿä¸€ä¸‹ï¼Œè®©è®­ç»ƒè¿‡ç¨‹æ›´æ˜æ˜¾
        time.sleep(0.02)
    
    print(f"\nâœ¨ è®­ç»ƒå®Œæˆï¼")
    print(f"  - æœ€ç»ˆå‚æ•°: w={w:.4f}, b={b:.4f}")
    print(f"  - æœ€ç»ˆæŸå¤±: {loss:.6f}")
    print(f"  - çœŸå®å‚æ•°: w=2.0000, b=3.0000")
    
    return loss, w, b


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="è¶…ç®€å•çº¿æ€§å›å½’è®­ç»ƒç¤ºä¾‹")
    parser.add_argument("--lr", type=float, default=0.05, help="å­¦ä¹ ç‡")
    parser.add_argument("--epochs", type=int, default=80, help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--samples", type=int, default=100, help="æ ·æœ¬æ•°")
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("  ğŸ”¬ ç®€å•çº¿æ€§å›å½’è®­ç»ƒ (ä¸éœ€è¦é¢å¤–ä¾èµ–)")
    print("=" * 60)
    print()
    
    # ç”Ÿæˆæ•°æ®
    X, y = generate_data(args.samples)
    
    # è®­ç»ƒ
    try:
        loss, w, b = train_linear_regression(X, y, args.lr, args.epochs)
        print("\nâœ“ è®­ç»ƒæˆåŠŸï¼")
        exit(0)
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå¤±è´¥: {e}")
        exit(1)

